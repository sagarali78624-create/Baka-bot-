# Copyright (c) 2025 Telegram:- @WTF_Phantom <DevixOP>
# Location: Supaul, Bihar 
#
# All rights reserved.
#
# This code is the intellectual property of @WTF_Phantom.
# You are not allowed to copy, modify, redistribute, or use this
# code for commercial or personal projects without explicit permission.
#
# Allowed:
# - Forking for personal learning
# - Submitting improvements via pull requests
#
# Not Allowed:
# - Claiming this code as your own
# - Re-uploading without credit or permission
# - Selling or using commercially
#
# Contact for permissions:
# Email: king25258069@gmail.com

import httpx
import random
import asyncio
from telegram import Update, InlineKeyboardMarkup, InlineKeyboardButton
from telegram.ext import ContextTypes
from telegram.constants import ParseMode, ChatAction, ChatType
from telegram.error import BadRequest
from baka.config import MISTRAL_API_KEY, GROQ_API_KEY, CODESTRAL_API_KEY, BOT_NAME, OWNER_LINK
from baka.database import chatbot_collection
from baka.utils import stylize_text  # Import back for output only

# --- ğŸ¨ BAKA PERSONALITY CONFIG ---
BAKA_NAME = "Baka"

# Rotating emoji pools (fresh every response)
EMOJI_POOL = ["âœ¨", "ğŸ’–", "ğŸŒ¸", "ğŸ˜Š", "ğŸ¥°", "ğŸ’•", "ğŸ€", "ğŸŒº", "ğŸ’«", "ğŸ¦‹", "ğŸŒ¼", "ğŸ’—", "ğŸ¨", "ğŸ“", "â˜ºï¸", "ğŸ˜Œ", "ğŸŒŸ", "ğŸ’"]

# --- ğŸ¤– MODEL SETTINGS ---
# Groq Working Models (Dec 2024):
# Auto-detection will find the best available model

GROQ_MODEL_PRIORITY = [
    "llama-3.3-70b-versatile",    # Try latest first
    "llama-3.1-70b-versatile",    # Best quality (free tier)
    "llama-3.1-8b-instant",       # Fastest
    "mixtral-8x7b-32768",         # Good balance
    "gemma2-9b-it"                # Backup option
]

MODELS = {
    "groq": {
        "url": "https://api.groq.com/openai/v1/chat/completions",
        "model": "llama-3.1-70b-versatile",  # Will be auto-updated
        "key": GROQ_API_KEY
    }
}

MAX_HISTORY = 8  # Reduced for faster responses
DEFAULT_MODEL = "groq"

# Cache for working Groq model (to avoid repeated checks)
_WORKING_GROQ_MODEL = None
_GROQ_MODEL_CHECKED = False

# --- ğŸ­ STICKER PACKS ---
STICKER_PACKS = [
    "https://t.me/addstickers/RandomByDarkzenitsu",
    "https://t.me/addstickers/Null_x_sticker_2",
    "https://t.me/addstickers/pack_73bc9_by_TgEmojis_bot",
    "https://t.me/addstickers/animation_0_8_Cat",
    "https://t.me/addstickers/vhelw_by_CalsiBot",
    "https://t.me/addstickers/Rohan_yad4v1745993687601_by_toWebmBot",
    "https://t.me/addstickers/MySet199",
    "https://t.me/addstickers/Quby741",
    "https://t.me/addstickers/Animalsasthegtjtky_by_fStikBot",
    "https://t.me/addstickers/a6962237343_by_Marin_Roxbot",
    "https://t.me/addstickers/cybercats_stickers"
]

FALLBACK_RESPONSES = [
    "Achha ji? ğŸ˜Š",
    "Hmm... aur batao?",
    "Okk okk! âœ¨",
    "Sahi hai yaar ğŸ’–",
    "Toh phir?",
    "Interesting! ğŸŒ¸",
    "Aur kya chal raha?",
    "Sunao sunao! ğŸ’•",
    "Haan haan",
    "Theek hai ğŸ¥°"
]

# --- ğŸ“¨ HELPER: SEND STICKER ---
async def send_ai_sticker(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Tries to send a random sticker from configured packs."""
    sent = False
    attempts = 0
    while not sent and attempts < 3:
        try:
            raw_link = random.choice(STICKER_PACKS)
            pack_name = raw_link.replace("https://t.me/addstickers/", "")
            sticker_set = await context.bot.get_sticker_set(pack_name)
            if sticker_set and sticker_set.stickers:
                sticker = random.choice(sticker_set.stickers)
                await update.message.reply_sticker(sticker.file_id)
                sent = True
        except:
            attempts += 1

# --- ğŸ§  AI CORE ENGINE ---

async def detect_working_groq_model():
    """
    Auto-detect which Groq model works with your API key.
    Tries models in priority order and caches the result.
    """
    global _WORKING_GROQ_MODEL, _GROQ_MODEL_CHECKED

    # Return cached result if already checked
    if _GROQ_MODEL_CHECKED:
        return _WORKING_GROQ_MODEL

    if not GROQ_API_KEY:
        print("âš ï¸ GROQ API key not configured")
        _GROQ_MODEL_CHECKED = True
        return None

    print("ğŸ” Auto-detecting working Groq model...")

    # Test each model with a simple query
    test_messages = [
        {"role": "user", "content": "Hi"}
    ]

    for model_name in GROQ_MODEL_PRIORITY:
        try:
            headers = {
                "Authorization": f"Bearer {GROQ_API_KEY}",
                "Content-Type": "application/json"
            }
            payload = {
                "model": model_name,
                "messages": test_messages,
                "max_tokens": 10,
                "temperature": 0.5
            }

            async with httpx.AsyncClient(timeout=10) as client:
                resp = await client.post(
                    MODELS["groq"]["url"],
                    json=payload,
                    headers=headers
                )

                if resp.status_code == 200:
                    print(f"âœ… Found working Groq model: {model_name}")
                    _WORKING_GROQ_MODEL = model_name
                    _GROQ_MODEL_CHECKED = True
                    MODELS["groq"]["model"] = model_name  # Update global config
                    return model_name
                else:
                    print(f"âŒ {model_name} not available (status {resp.status_code})")

        except Exception as e:
            print(f"âŒ {model_name} test failed: {str(e)[:50]}")
            continue

    print("âš ï¸ No working Groq model found")
    _GROQ_MODEL_CHECKED = True
    return None


async def call_model_api(provider, messages, max_tokens):
    """Generic function to call any configured AI API."""

    # Auto-detect Groq model on first use
    if provider == "groq" and not _GROQ_MODEL_CHECKED:
        await detect_working_groq_model()

    conf = MODELS.get(provider)

    # Check if API key exists
    if not conf or not conf["key"]:
        print(f"âš ï¸ {provider.upper()} API key not configured")
        return None

    headers = {
        "Authorization": f"Bearer {conf['key']}",
        "Content-Type": "application/json"
    }
    payload = {
        "model": conf["model"],
        "messages": messages,
        "temperature": 0.8,
        "max_tokens": max_tokens,
        "top_p": 0.9
    }

    try:
        async with httpx.AsyncClient(timeout=25) as client:
            resp = await client.post(conf["url"], json=payload, headers=headers)

            if resp.status_code == 200:
                result = resp.json()["choices"][0]["message"]["content"]
                print(f"âœ… {provider.upper()} API responded successfully")
                return result
            else:
                print(f"âš ï¸ {provider.upper()} API returned status {resp.status_code}: {resp.text[:100]}")
                return None

    except httpx.TimeoutException:
        print(f"â° {provider.upper()} API timeout")
        return None
    except Exception as e:
        print(f"âŒ {provider.upper()} API error: {str(e)[:100]}")
        return None


async def get_ai_response(chat_id: int, user_input: str, user_name: str, selected_model=DEFAULT_MODEL):
    """
    ğŸ¯ The Master AI Function
    
    Flow:
    1. Detects if user wants code â†’ Auto-switches to Codestral
    2. Matches user's energy level (short replies for short messages)
    3. Uses natural Hinglish without fancy Unicode
    4. Anti-repetition protection
    """

    # --- 1ï¸âƒ£ CODE DETECTION ---
    code_keywords = [
        "code", "python", "html", "css", "javascript", "script", 
        "function", "fix", "error", "debug", "java", "algorithm",
        "program", "syntax", "class", "import", "def ", "npm", "install"
    ]
    is_coding_request = any(kw in user_input.lower() for kw in code_keywords)

    if is_coding_request:
        active_model = "codestral"
        max_tokens = 4096
        # ğŸ–¥ï¸ Codestral Persona (Technical, Clean)
        system_prompt = (
            "You are a professional coding assistant. "
            "Provide clean, working, well-commented code. "
            "Explain briefly but precisely. No emojis in code blocks. "
            "Support Python, JavaScript, HTML, CSS, Java, C++."
        )
    else:
        active_model = selected_model

        # Detect if short greeting
        is_short_msg = len(user_input.split()) <= 3
        max_tokens = 100 if is_short_msg else 200

        # ğŸ’• Baka Persona (Natural Indian Girlfriend)
        emoji_set = random.sample(EMOJI_POOL, 2)  # Just 2 emojis
        system_prompt = (
            f"You are {BAKA_NAME}, a sweet Indian girlfriend who speaks natural Hinglish.\n\n"
            "PERSONALITY:\n"
            "- Playful but not over-dramatic\n"
            "- Uses simple Hindi+English mix (e.g., 'Kya hua baby?', 'Achha theek hai')\n"
            "- Warm, caring, sometimes teasing\n"
            "- Emojis: 1-2 per message maximum\n\n"
            "RULES:\n"
            "1. Match user's energy:\n"
            "   - Short message (Hi/Hey) â†’ Reply in 1 short sentence\n"
            "   - Long message â†’ Can reply with 2-3 sentences\n"
            "2. NO asterisk actions (*does this*) - just talk naturally\n"
            "3. NO repetition - check conversation history\n"
            "4. Be direct and real, like actual texting\n"
            "5. Don't overuse emojis - keep it subtle\n"
            "6. Never mention you're an AI\n\n"
            f"Example good replies:\n"
            "User: Hi\n"
            "You: Hey baby! Kya hua? ğŸ’•\n\n"
            "User: Kaise ho?\n"
            "You: Ekdum badhiya! Tum batao? ğŸ˜Š\n\n"
            "User: Bore ho raha\n"
            "You: Aww, chalo kuch baat karte hain na! âœ¨"
        )

    # --- 2ï¸âƒ£ BUILD CONTEXT ---
    doc = chatbot_collection.find_one({"chat_id": chat_id}) or {}
    history = doc.get("history", [])

    messages = [{"role": "system", "content": system_prompt}]

    # Add recent context (last 8 exchanges)
    for msg in history[-MAX_HISTORY:]:
        messages.append(msg)

    # Add current message
    messages.append({"role": "user", "content": user_input})

    # --- 3ï¸âƒ£ ATTEMPT GENERATION (Smart Fallback Chain) ---
    reply = None

    # Try 1: User's preferred model (or auto-selected for code)
    print(f"ğŸ¯ Attempting {active_model.upper()} (primary choice)")
    reply = await call_model_api(active_model, messages, max_tokens)

    # Try 2: Fallback to Mistral (if available and not already tried)
    if not reply and active_model != "mistral":
        print(f"ğŸ”„ Falling back to MISTRAL")
        reply = await call_model_api("mistral", messages, max_tokens)

    # Try 3: Fallback to Groq (if available and not already tried)
    if not reply and active_model != "groq":
        print(f"ğŸ”„ Falling back to GROQ")
        reply = await call_model_api("groq", messages, max_tokens)

    # Try 4: Last attempt - try the one we haven't tried yet
    if not reply:
        for model_name in ["groq", "mistral", "codestral"]:
            if model_name != active_model and MODELS[model_name]["key"]:
                print(f"ğŸ”„ Final attempt with {model_name.upper()}")
                reply = await call_model_api(model_name, messages, max_tokens)
                if reply:
                    break

    # Fallback 5: Hardcoded responses
    if not reply:
        print("âš ï¸ All APIs failed, using hardcoded response")
        return random.choice(FALLBACK_RESPONSES), is_coding_request

    # --- 4ï¸âƒ£ CLEANUP ---
    # Remove any asterisk actions if AI added them
    reply = reply.replace('*', '').strip()

    # Anti-loop: Check if repeating last response
    if history and len(history) >= 2:
        last_assistant = next((h['content'] for h in reversed(history) if h['role'] == 'assistant'), None)
        if last_assistant and reply.lower().strip() == last_assistant.lower().strip():
            reply = random.choice(FALLBACK_RESPONSES)

    # --- 5ï¸âƒ£ SAVE MEMORY ---
    # Save NORMAL text in history (so AI can read it properly)
    new_history = history + [
        {"role": "user", "content": user_input},
        {"role": "assistant", "content": reply}  # Store plain text
    ]

    # Keep only recent context
    if len(new_history) > MAX_HISTORY * 2:
        new_history = new_history[-(MAX_HISTORY * 2):]

    chatbot_collection.update_one(
        {"chat_id": chat_id},
        {"$set": {"history": new_history}},
        upsert=True
    )

    return reply, is_coding_request


# --- ğŸ® SHARED AI FUNCTION (FOR GAMES/OTHER FEATURES) ---
async def ask_mistral_raw(system_prompt, user_input, max_tokens=150):
    """Quick AI call without memory (for games, etc.)"""
    msgs = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_input}
    ]

    # Try Mistral first
    res = await call_model_api("mistral", msgs, max_tokens)

    # Fallback to Groq
    if not res:
        res = await call_model_api("groq", msgs, max_tokens)

    # Try any available model as last resort
    if not res:
        for model in ["codestral", "groq", "mistral"]:
            if MODELS[model]["key"]:
                res = await call_model_api(model, msgs, max_tokens)
                if res:
                    break

    return res


# --- âš™ï¸ SETTINGS MENU ---

async def chatbot_menu(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """
    /chatbot command - Settings panel
    - PMs: Always enabled (can't disable, only switch model)
    - Groups: Admins can enable/disable + switch model
    """
    chat = update.effective_chat
    user = update.effective_user

    # Private Message: Show model switcher only
    if chat.type == ChatType.PRIVATE:
        doc = chatbot_collection.find_one({"chat_id": chat.id})
        curr_model = doc.get("model", DEFAULT_MODEL) if doc else DEFAULT_MODEL

        kb = InlineKeyboardMarkup([
            [
                InlineKeyboardButton("ğŸ¦™ Groq", callback_data="ai_set_groq"),
                InlineKeyboardButton("ğŸŒŸ Mistral", callback_data="ai_set_mistral")
            ],
            [InlineKeyboardButton("ğŸ–¥ï¸ Codestral (Code)", callback_data="ai_set_codestral")],
            [InlineKeyboardButton("ğŸ—‘ï¸ Clear Memory", callback_data="ai_reset")]
        ])

        return await update.message.reply_text(
            f"ğŸ¤– <b>Baka AI Settings</b>\n\n"
            f"ğŸ“ <b>Current Model:</b> {curr_model.title()}\n"
            f"ğŸ’¡ <b>Tip:</b> Codestral auto-activates for code requests!",
            parse_mode=ParseMode.HTML,
            reply_markup=kb
        )

    # Group Chat: Admin check
    member = await chat.get_member(user.id)
    if member.status not in ['administrator', 'creator']:
        return await update.message.reply_text(
            "âŒ Only admins can change AI settings!",
            parse_mode=ParseMode.HTML
        )

    # Get current settings
    doc = chatbot_collection.find_one({"chat_id": chat.id})
    is_enabled = doc.get("enabled", True) if doc else True
    curr_model = doc.get("model", DEFAULT_MODEL) if doc else DEFAULT_MODEL

    status_emoji = "ğŸŸ¢" if is_enabled else "ğŸ”´"
    status_text = "Enabled" if is_enabled else "Disabled"

    kb = InlineKeyboardMarkup([
        [
            InlineKeyboardButton("âœ… Enable", callback_data="ai_enable"),
            InlineKeyboardButton("âŒ Disable", callback_data="ai_disable")
        ],
        [
            InlineKeyboardButton("ğŸ¦™ Groq", callback_data="ai_set_groq"),
            InlineKeyboardButton("ğŸŒŸ Mistral", callback_data="ai_set_mistral")
        ],
        [InlineKeyboardButton("ğŸ–¥ï¸ Codestral (Code)", callback_data="ai_set_codestral")],
        [InlineKeyboardButton("ğŸ—‘ï¸ Clear Memory", callback_data="ai_reset")]
    ])

    await update.message.reply_text(
        f"ğŸ¤– <b>Baka AI Settings</b>\n\n"
        f"ğŸ“Š <b>Status:</b> {status_emoji} {status_text}\n"
        f"ğŸ§  <b>Model:</b> {curr_model.title()}\n"
        f"ğŸ’¡ <b>Tip:</b> Codestral auto-activates for code!",
        parse_mode=ParseMode.HTML,
        reply_markup=kb
    )


async def chatbot_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Handle button clicks in /chatbot menu"""
    query = update.callback_query
    data = query.data
    chat_id = query.message.chat.id
    chat_type = query.message.chat.type

    # Admin check (only for groups)
    if chat_type != ChatType.PRIVATE:
        mem = await query.message.chat.get_member(query.from_user.id)
        if mem.status not in ['administrator', 'creator']:
            return await query.answer("âŒ Admin Only", show_alert=True)

    # --- ENABLE/DISABLE (Groups only) ---
    if data == "ai_enable":
        if chat_type == ChatType.PRIVATE:
            return await query.answer("âš ï¸ AI is always on in PMs!", show_alert=True)

        chatbot_collection.update_one(
            {"chat_id": chat_id},
            {"$set": {"enabled": True}},
            upsert=True
        )
        await query.answer("âœ… Baka is now active!", show_alert=True)
        await query.message.edit_text(
            "âœ… <b>Baka AI Enabled!</b>\n\nShe'll respond to:\nâ€¢ Replies to her messages\nâ€¢ @mentions\nâ€¢ Messages starting with 'hey', 'hi', 'baka'",
            parse_mode=ParseMode.HTML
        )

    elif data == "ai_disable":
        if chat_type == ChatType.PRIVATE:
            return await query.answer("âš ï¸ Can't disable in PMs!", show_alert=True)

        chatbot_collection.update_one(
            {"chat_id": chat_id},
            {"$set": {"enabled": False}},
            upsert=True
        )
        await query.answer("âŒ Baka is now silent!", show_alert=True)
        await query.message.edit_text(
            "ğŸ”‡ <b>Baka AI Disabled</b>\n\nUse /chatbot to re-enable anytime.",
            parse_mode=ParseMode.HTML
        )

    # --- MODEL SWITCHING ---
    elif data in ["ai_set_groq", "ai_set_mistral", "ai_set_codestral"]:
        model_map = {
            "ai_set_groq": "groq",
            "ai_set_mistral": "mistral",
            "ai_set_codestral": "codestral"
        }
        new_model = model_map[data]

        chatbot_collection.update_one(
            {"chat_id": chat_id},
            {"$set": {"model": new_model}},
            upsert=True
        )

        model_names = {
            "groq": "ğŸ¦™ Groq (Fast)",
            "mistral": "ğŸŒŸ Mistral (Smart)",
            "codestral": "ğŸ–¥ï¸ Codestral (Code)"
        }

        await query.answer(f"Switched to {model_names[new_model]}!", show_alert=True)

        # Refresh menu
        doc = chatbot_collection.find_one({"chat_id": chat_id})
        is_enabled = doc.get("enabled", True) if doc else True
        status_emoji = "ğŸŸ¢" if is_enabled else "ğŸ”´"

        kb = InlineKeyboardMarkup([
            [
                InlineKeyboardButton("âœ… Enable", callback_data="ai_enable"),
                InlineKeyboardButton("âŒ Disable", callback_data="ai_disable")
            ] if chat_type != ChatType.PRIVATE else [],
            [
                InlineKeyboardButton("ğŸ¦™ Groq", callback_data="ai_set_groq"),
                InlineKeyboardButton("ğŸŒŸ Mistral", callback_data="ai_set_mistral")
            ],
            [InlineKeyboardButton("ğŸ–¥ï¸ Codestral", callback_data="ai_set_codestral")],
            [InlineKeyboardButton("ğŸ—‘ï¸ Clear Memory", callback_data="ai_reset")]
        ])

        await query.message.edit_text(
            f"ğŸ¤– <b>Baka AI Settings</b>\n\n"
            f"{'ğŸ“Š <b>Status:</b> ' + status_emoji + (' Enabled' if is_enabled else ' Disabled') + chr(10) if chat_type != ChatType.PRIVATE else ''}"
            f"ğŸ§  <b>Model:</b> {model_names[new_model]}\n"
            f"ğŸ’¡ <b>Note:</b> Codestral auto-activates for code!",
            parse_mode=ParseMode.HTML,
            reply_markup=kb
        )

    # --- CLEAR MEMORY ---
    elif data == "ai_reset":
        chatbot_collection.update_one(
            {"chat_id": chat_id},
            {"$set": {"history": []}},
            upsert=True
        )
        await query.answer("ğŸ§  Memory wiped! Fresh start!", show_alert=True)


# --- ğŸ’¬ MESSAGE HANDLER ---

async def ai_message_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """
    Main handler for AI conversations
    - Always active in PMs
    - In groups: Only when enabled + (reply/mention/greeting)
    """
    msg = update.message
    if not msg:
        return

    chat = update.effective_chat

    # --- STICKER RESPONSE ---
    if msg.sticker:
        should_react = (
            chat.type == ChatType.PRIVATE or
            (msg.reply_to_message and msg.reply_to_message.from_user.id == context.bot.id)
        )
        if should_react:
            await send_ai_sticker(update, context)
        return

    # --- TEXT PROCESSING ---
    if not msg.text or msg.text.startswith("/"):
        return

    text = msg.text.strip()
    if not text:
        return

    # --- DECIDE IF SHOULD REPLY ---
    should_reply = False

    if chat.type == ChatType.PRIVATE:
        # Always reply in PMs
        should_reply = True
    else:
        # Groups: Check if enabled
        doc = chatbot_collection.find_one({"chat_id": chat.id})
        is_enabled = doc.get("enabled", True) if doc else True

        if not is_enabled:
            return

        # Check triggers
        bot_username = context.bot.username.lower() if context.bot.username else "bot"

        # 1. Reply to bot's message
        if msg.reply_to_message and msg.reply_to_message.from_user.id == context.bot.id:
            should_reply = True

        # 2. @mention
        elif f"@{bot_username}" in text.lower():
            should_reply = True
            text = text.replace(f"@{bot_username}", "").strip()

        # 3. Greeting keywords
        elif any(text.lower().startswith(kw) for kw in ["hey", "hi", "hello", "sun", "oye", "baka", "ai"]):
            should_reply = True

    # --- GENERATE RESPONSE ---
    if should_reply:
        if not text:
            text = "Hi"

        # Show typing indicator
        await context.bot.send_chat_action(chat_id=chat.id, action=ChatAction.TYPING)

        # Get user's preferred model
        doc = chatbot_collection.find_one({"chat_id": chat.id})
        pref_model = doc.get("model", DEFAULT_MODEL) if doc else DEFAULT_MODEL

        # Get AI response
        response, is_code = await get_ai_response(
            chat.id,
            text,
            msg.from_user.first_name,
            pref_model
        )

        # --- FORMAT & SEND ---
        if is_code:
            # Code: Use Markdown for proper formatting (NO stylize)
            await msg.reply_text(response, parse_mode=ParseMode.MARKDOWN)
        else:
            # Conversation: Stylize ONLY the output (not history)
            styled_response = stylize_text(response)
            await msg.reply_text(styled_response)

        # Random sticker (20% chance, not for code)
        if not is_code and random.random() < 0.20:
            await send_ai_sticker(update, context)


# --- ğŸ”§ COMMAND: /ask ---

async def ask_ai(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """
    Direct AI query: /ask <question>
    Always uses default model (Mistral) unless code detected
    """
    msg = update.message

    if not context.args:
        return await msg.reply_text(
            "ğŸ’¬ <b>Usage:</b> <code>/ask Your question here</code>\n\n"
            "Example: <code>/ask Kya chal raha?</code>",
            parse_mode=ParseMode.HTML
        )

    await context.bot.send_chat_action(chat_id=msg.chat.id, action=ChatAction.TYPING)

    query = " ".join(context.args)
    response, is_code = await get_ai_response(
        msg.chat.id,
        query,
        msg.from_user.first_name,
        DEFAULT_MODEL
    )

    if is_code:
        await msg.reply_text(response, parse_mode=ParseMode.MARKDOWN)
    else:
        # Stylize output only (history stays clean)
        styled_response = stylize_text(response)
        await msg.reply_text(styled_response)
